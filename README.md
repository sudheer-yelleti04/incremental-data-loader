ğŸ§© Change Data Capture (CDC) Automation System

>ğŸ“˜ Project Description

This project automates a Change Data Capture (CDC) pipeline using Python and Excel files â€” ideal for small to mid-scale data engineering use cases or prototyping CDC before moving to a database or Airflow environment.

The pipeline reads new raw data files (Excel), tracks changes using Status Flags (I, U, D) and Timestamps, and maintains:

* CDC Layer (latest snapshot)
* Historic Layer (complete history of all events)
* Backup Layer (archive of processed raw files)

Each new raw file is automatically processed, appended to history, compared against existing data, and the latest CDC snapshot is updated.

>ğŸ—ï¸ Folder Structure
<img width="843" height="276" alt="image" src="https://github.com/user-attachments/assets/7cde9ee6-cd60-4401-9110-afe3e1fa634c" />


* ğŸ§  How It Works

>ğŸ©¸ Step 1 â€” (Raw Layer)

Drop your latest Excel file into the raw_folder/.
Each file must contain:
ID, Statusflag (I, U, D), and Timestamp columns.

Example:

| ID | Name         | Email                                     | Statusflag | Timestamp           |
| -- | ------------ | ----------------------------------------- | ---------- | ------------------- |
| 1  | John Smith   | [john@email.com](mailto:john@email.com)   | I          | 2025-11-01 10:00:00 |
| 1  | John Smith   | [john@email.com](mailto:john@email.com)   | U          | 2025-11-03 14:30:00 |
| 2  | Priya Sharma | [priya@email.com](mailto:priya@email.com) | I          | 2025-11-04 09:15:00 |

>ğŸ§¾ Step 2 â€” (Historic Layer)

The system appends every incoming record to a single Excel file:
historic_folder/historic_data.xlsx

ğŸ•“ This acts as a full audit trail â€” nothing is ever deleted here.

>ğŸ§® Step 3 â€” (CDC Layer)

The script merges the new raw data with the existing CDC snapshot:

* Sorts by ID and Timestamp
* Keeps only the latest record per ID
* Removes records where Statusflag = D

ğŸŸ¢ Output â†’ cdc_folder/cdc_data_latest.xlsx
(always exactly one file, representing the latest state)

>ğŸ—„ï¸ Step 4 â€” (Archive Layer)

After processing, the raw Excel file is timestamped and moved to:
archived_folder/

Example:
archived_folder/raw_data_2025_11_05_20251105_144533.xlsx

>âš™ï¸ Run Instructions

1ï¸âƒ£ Create Environment

bash
python -m venv venv
source venv/bin/activate       # macOS/Linux
OR
venv\Scripts\activate          # Windows


2ï¸âƒ£ Install Dependencies

bash
pip install pandas openpyxl

3ï¸âƒ£ Run Script

bash
python cdc_script.py

4ï¸âƒ£ Check Outputs

* ğŸ“œ historic_folder/historic_data.xlsx â†’ all event history
* ğŸ“Š cdc_folder/cdc_data_latest.xlsx â†’ latest snapshot
* ğŸ“¦ archived_folder/ â†’ archived raw file

>ğŸ§© CDC Logic Explained

| Flag | Meaning | Behavior in CDC Layer             |
| ---- | ------- | --------------------------------- |
| I    | Insert  | New record is added               |
| U    | Update  | Old record replaced with new data |
| D    | Delete  | Record removed from CDC snapshot  |

>ğŸ§¾ Example Output Summary

ğŸ“‚ Using latest raw file: raw_folder/raw_data_2025_11_05.xlsx
ğŸ•“ Historic layer updated: historic_folder/historic_data.xlsx
âœ… CDC layer updated: cdc_folder/cdc_data_latest.xlsx

>ğŸ“Š Change Summary

  Inserted: 3 records
  Updated: 4 records
  Deleted: 1 records

ğŸ“¦ Moved raw file to backup: archived_folder/raw_data_2025_11_05_20251105_144533.xlsx
ğŸ¯ CDC + Historic process completed successfully!

ğŸ› ï¸ Technologies Used

| Tool          | Purpose                     |
| ------------- | --------------------------- |
| ğŸ Python     | Main language               |
| ğŸ§® Pandas     | Data processing & CDC logic |
| ğŸ“˜ OpenPyXL   | Excel I/O operations        |
| ğŸ§° OS, Shutil | File and folder management  |

>âœ… Key Advantages

* ğŸ§¾ Transparent, human-readable Excel pipeline
* ğŸ” Maintains both historic & current datasets
* ğŸ’¾ Automatically handles backup and cleanup
* ğŸ§  Simple, modular, and Airflow-ready
* ğŸŒ Cross-platform and lightweight

>âš ï¸ Limitations

* âŒ Not suitable for very large datasets (>100K rows)
* âŒ Sequential file processing only (single-threaded)
* âŒ No inbuilt data validation â€” assumes clean input
* âŒ Excel-based I/O can slow down large ETL workloads

>ğŸš€ Future Enhancements

* ğŸ§® Add cdc_run_log.xlsx to capture run stats
* â° Integrate with Apache Airflow for scheduling
* ğŸ—ƒï¸ Upgrade to SQL/Delta Lake storage
* ğŸ§© Add schema validation & data quality checks
* ğŸ“ˆ Include dashboard/reporting module


>ğŸ‘¨â€ğŸ’» Author

Yelleti Sudheer Kumar
ğŸ’¼ Data Engineering Enthusiast | ETL | Python | Airflow
ğŸ“§ sudheeryelleti@gmail.com

>ğŸŒŸ Support

If you like this project, please â­ star the repository â€” it helps others discover it!
Contributions and suggestions are always welcome ğŸ’¬
